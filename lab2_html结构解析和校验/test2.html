<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</title>
  <meta name="description" content="Chain of thought prompting enables models to generate intermediate reasoning steps to help solve multi-step arithmetic, commonsense, and symbolic reasoning tasks." />
</head>
<body>
  <main>
    <h1>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h1>

    <p><strong>Authors:</strong> Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, Denny Zhou</p>
    <p><strong>Published:</strong> 31 Oct 2022</p>
    <p><strong>Venue:</strong> NeurIPS 2022 Accept</p>

    <p>
      <a href="https://openreview.net/pdf?id=_VjQlMeSB_J" target="_blank" rel="noopener">Download PDF</a>
      &nbsp;|&nbsp;
      <a href="https://openreview.net/attachment?id=_VjQlMeSB_J&amp;name=supplementary_material" target="_blank" rel="noopener">Supplementary Material</a>
    </p>

    <section>
      <h2>TL;DR</h2>
      <p>Chain of thought prompting enables models to generate intermediate reasoning steps to help solve multi-step arithmetic, commonsense, and symbolic reasoning tasks.</p>
    </section>

    <section>
      <h2>Abstract</h2>
      <p>
        We explore how generating a chain of thought — a series of intermediate reasoning steps — significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.
      </p>

    <section>
      <h2>Keywords</h1>
      <ul>
        <li>Language models</li>
        <li>Natural language processing</li>
        <li>Reasoning</li>
      </ul>
    </section>
  </main>
</body>
</html>